{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0061d4df",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa4add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44d41624",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc0c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1699067/1699067 [00:17<00:00, 96960.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>frag_1</th>\n",
       "      <th>frag_2</th>\n",
       "      <th>h_bond_distance</th>\n",
       "      <th>frag_3</th>\n",
       "      <th>frag_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000000</td>\n",
       "      <td>TLGR</td>\n",
       "      <td>VALV</td>\n",
       "      <td>15.0</td>\n",
       "      <td>RGLT</td>\n",
       "      <td>VLAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0000001</td>\n",
       "      <td>AILTCPF</td>\n",
       "      <td>GRIVPRF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FPCTLIA</td>\n",
       "      <td>FRPVIRG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0000002</td>\n",
       "      <td>LRLSCA</td>\n",
       "      <td>MQLYVT</td>\n",
       "      <td>17.0</td>\n",
       "      <td>ACSLRL</td>\n",
       "      <td>TVYLQM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0000003</td>\n",
       "      <td>TASVVCLLNN</td>\n",
       "      <td>SLTLTSSLSY</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NNLLCVVSAT</td>\n",
       "      <td>YSLSSTLTLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0000004</td>\n",
       "      <td>VKLYL</td>\n",
       "      <td>ILVSD</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LYLKV</td>\n",
       "      <td>DSVLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699062</th>\n",
       "      <td>TRAIN_1699062</td>\n",
       "      <td>LMLVHYEGYL</td>\n",
       "      <td>IELLDINFIL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LYGEYHVLML</td>\n",
       "      <td>LIFNIDLLEI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699063</th>\n",
       "      <td>TRAIN_1699063</td>\n",
       "      <td>MLIT</td>\n",
       "      <td>IFPV</td>\n",
       "      <td>16.0</td>\n",
       "      <td>TILM</td>\n",
       "      <td>VPFI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699064</th>\n",
       "      <td>TRAIN_1699064</td>\n",
       "      <td>IYLGRYEGWYS</td>\n",
       "      <td>MYNEESVWTVV</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SYWGEYRGLYI</td>\n",
       "      <td>VVTWVSEENYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699065</th>\n",
       "      <td>TRAIN_1699065</td>\n",
       "      <td>KFWLIYTD</td>\n",
       "      <td>CTTLYNHC</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DTYILWFK</td>\n",
       "      <td>CHNYLTTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699066</th>\n",
       "      <td>TRAIN_1699066</td>\n",
       "      <td>GFALVYS</td>\n",
       "      <td>PMILVGN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SYVLAFG</td>\n",
       "      <td>NGVLIMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699067 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID       frag_1       frag_2  h_bond_distance  \\\n",
       "0        TRAIN_0000000         TLGR         VALV             15.0   \n",
       "1        TRAIN_0000001      AILTCPF      GRIVPRF             20.0   \n",
       "2        TRAIN_0000002       LRLSCA       MQLYVT             17.0   \n",
       "3        TRAIN_0000003   TASVVCLLNN   SLTLTSSLSY             25.0   \n",
       "4        TRAIN_0000004        VKLYL        ILVSD             19.0   \n",
       "...                ...          ...          ...              ...   \n",
       "1699062  TRAIN_1699062   LMLVHYEGYL   IELLDINFIL             24.0   \n",
       "1699063  TRAIN_1699063         MLIT         IFPV             16.0   \n",
       "1699064  TRAIN_1699064  IYLGRYEGWYS  MYNEESVWTVV             24.0   \n",
       "1699065  TRAIN_1699065     KFWLIYTD     CTTLYNHC             21.0   \n",
       "1699066  TRAIN_1699066      GFALVYS      PMILVGN             19.0   \n",
       "\n",
       "              frag_3       frag_4  \n",
       "0               RGLT         VLAV  \n",
       "1            FPCTLIA      FRPVIRG  \n",
       "2             ACSLRL       TVYLQM  \n",
       "3         NNLLCVVSAT   YSLSSTLTLS  \n",
       "4              LYLKV        DSVLI  \n",
       "...              ...          ...  \n",
       "1699062   LYGEYHVLML   LIFNIDLLEI  \n",
       "1699063         TILM         VPFI  \n",
       "1699064  SYWGEYRGLYI  VVTWVSEENYM  \n",
       "1699065     DTYILWFK     CHNYLTTC  \n",
       "1699066      SYVLAFG      NGVLIMP  \n",
       "\n",
       "[1699067 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df[\"frag_3\"] = 0\n",
    "df[\"frag_4\"] = 0\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    df[\"frag_3\"][i] = df[\"frag_1\"][i][::-1]\n",
    "    df[\"frag_4\"][i] = df[\"frag_2\"][i][::-1]\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219dc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"check_cha\"] = 0\n",
    "df[\"check_num\"] = 0\n",
    "\n",
    "sosu = [\"V\", \"L\", \"I\", \"A\", \"F\", \"Y\", \"M\", \"W\", \"G\", \"P\"] # 소수성\n",
    "kuk = [\"T\", \"S\", \"N\",\"Q\",\"C\"] # 극성\n",
    "san = [\"E\",\"D\"] # 산성\n",
    "yum = [\"H\",\"R\",\"K\"] # 염기성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb8d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1699067/1699067 [00:33<00:00, 51022.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4가지 경우의 수\n",
    "frag_1 첫글자 - frag_2 첫글자\n",
    "frag_1 첫글자 - frag_2 마지막글자\n",
    "frag_1 마지막글자 - frag_2 첫글자\n",
    "frag_1 마지막글자 - frag_2 마지막글자\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "그 안에서 \n",
    "1. 산성 - 염기성인지 찾음\n",
    "2. 염기성 - 산성인지 찾음\n",
    "\"\"\"\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "\n",
    "    \"\"\"\n",
    "    frag_1 의 첫글자 - frag_2 첫글자\n",
    "    \"\"\"        \n",
    "        \n",
    "    if df[\"frag_1\"][i][0] in san and df[\"frag_2\"][i][0] in yum:\n",
    "        df[\"check_cha\"][i] = \"1-sanyum\"\n",
    "    if df[\"frag_1\"][i][0] in yum and df[\"frag_2\"][i][0] in san:\n",
    "        df[\"check_cha\"][i] = \"1-sanyum\"    \n",
    "    \n",
    "    \"\"\"\n",
    "    frag_1 첫글자 - frag_2 마지막글자\n",
    "    \"\"\"\n",
    "\n",
    "    if df[\"frag_1\"][i][0] in san and df[\"frag_2\"][i][-1] in yum:\n",
    "        df[\"check_cha\"][i] = \"2-sanyum\"\n",
    "    if df[\"frag_1\"][i][0] in yum and df[\"frag_2\"][i][-1] in san:\n",
    "        df[\"check_cha\"][i] = \"2-sanyum\"\n",
    "        \n",
    "    \"\"\"\n",
    "    frag_1 마지막글자 - frag_2 첫글자\n",
    "    \"\"\"\n",
    "\n",
    "    if df[\"frag_1\"][i][-1] in san and df[\"frag_2\"][i][0] in yum:\n",
    "        df[\"check_cha\"][i] = \"3-sanyum\"\n",
    "    if df[\"frag_1\"][i][-1] in yum and df[\"frag_2\"][i][0] in san:\n",
    "        df[\"check_cha\"][i] = \"3-sanyum\"            \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    frag_1 마지막글자 - frag_2 마지막글자\n",
    "    \"\"\"\n",
    "\n",
    "    if df[\"frag_1\"][i][-1] in san and df[\"frag_2\"][i][-1] in yum:\n",
    "        df[\"check_cha\"][i] = \"4-sanyum\"\n",
    "    if df[\"frag_1\"][i][-1] in yum and df[\"frag_2\"][i][-1] in san:\n",
    "        df[\"check_cha\"][i] = \"4-sanyum\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d7c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1699067/1699067 [00:15<00:00, 110416.78it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"comb\"] = 0\n",
    "\n",
    "\"\"\"\n",
    "df[\"comb1\"] = df[\"frag_1\"] + df[\"frag_2\"] 첨글자 + 첨글자\n",
    "df[\"comb2\"] = df[\"frag_1\"] + df[\"frag_4\"] 첨글자 + 마지막 글자\n",
    "df[\"comb3\"] = df[\"frag_2\"] + df[\"frag_1\"] 마지막 글자 + 첨글자\n",
    "df[\"comb4\"] = df[\"frag_2\"] + df[\"frag_3\"] 마지막 글자 + 마지막 글자\n",
    "\"\"\"\n",
    "#산성염기성 결합이면 combination 값을 ['comb']에 넣음 (두 단백질 붙인 sequence)\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df[\"check_cha\"][i] == \"4-sanyum\":\n",
    "        df[\"comb\"][i] = df[\"frag_2\"][i] + df[\"frag_3\"][i]\n",
    "    if df[\"check_cha\"][i] == \"3-sanyum\":\n",
    "        df[\"comb\"][i] = df[\"frag_2\"][i] + df[\"frag_1\"][i]\n",
    "    if df[\"check_cha\"][i] == \"2-sanyum\":\n",
    "        df[\"comb\"][i] = df[\"frag_1\"][i] + df[\"frag_4\"][i]\n",
    "    if df[\"check_cha\"][i] == \"1-sanyum\":\n",
    "        df[\"comb\"][i] = df[\"frag_1\"][i] + df[\"frag_2\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b1bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수성-소수성/ 극성-극성은 뺌\n",
    "df = df[df[\"check_cha\"] != 0]\n",
    "\n",
    "df = df[[\"comb\", \"h_bond_distance\"]]\n",
    "\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "259a4711",
   "metadata": {},
   "source": [
    "\n",
    "## 결합된 두 Protein의 길이 32로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f9bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157000/157000 [00:01<00:00, 136916.80it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"comb1\"] = 0\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if len(df[\"comb\"][i])<=32:\n",
    "        df[\"comb1\"][i] = df[\"comb\"][i]\n",
    "    else:\n",
    "        df[\"comb1\"][i] = df[\"comb\"][i][(len(df[\"comb\"][i])//2) -16:(len(df[\"comb\"][i])//2) + 16]\n",
    "\n",
    "df = df[[\"comb1\", \"h_bond_distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b395e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SEQ_MAX_LEN':32,\n",
    "    'EPOCHS':6,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':1024,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "x_train, x_test, _, _ = train_test_split(df, df[\"h_bond_distance\"], test_size=0.3, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5910e",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "## 알파벳 총 20개 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "411f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing(df):\n",
    "    # 그냥 알파벳 순서\n",
    "    alpha_map = {\n",
    "        '<PAD>': 0, 'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5,\n",
    "        'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "        'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15,\n",
    "        'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "        'Y': 20\n",
    "    }\n",
    "\n",
    "    frag1_list = []\n",
    "    \n",
    "    for frag1 in tqdm(df['comb1']):\n",
    "        frag1_pad = [alpha_map['<PAD>'] for _ in range(CFG['SEQ_MAX_LEN'])]\n",
    "        frag1_seq = [alpha_map[x] for x in frag1]\n",
    "\n",
    "        if CFG['SEQ_MAX_LEN']<len(frag1):\n",
    "            frag1_pad[:len(frag1)] = frag1_seq[:CFG['SEQ_MAX_LEN']]\n",
    "        else:\n",
    "            frag1_pad[:len(frag1)] = frag1_seq[:]\n",
    "\n",
    "        frag1_list.append(frag1_pad)\n",
    "    print('Done.')\n",
    "    return frag1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d481953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, frag1_list, dist_list):\n",
    "        self.frag1_list = frag1_list\n",
    "        self.dist_list = dist_list\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        self.frag1 = self.frag1_list[index]\n",
    "        \n",
    "        if self.dist_list is not None:\n",
    "            self.dist = self.dist_list[index]\n",
    "            return torch.tensor(self.frag1), self.dist\n",
    "        else:\n",
    "            return torch.tensor(self.frag1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frag1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5abfb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109900/109900 [00:00<00:00, 404897.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47100/47100 [00:00<00:00, 507976.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_frag1_list = get_preprocessing(x_train)\n",
    "val_frag1_list = get_preprocessing(x_test)\n",
    "\n",
    "train_dataset = CustomDataset(train_frag1_list, x_train['h_bond_distance'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_frag1_list, x_test['h_bond_distance'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5870713f",
   "metadata": {},
   "source": [
    "# Model (CNN + LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim=140,\n",
    "                 seq_dim=512,\n",
    "                 lstm_bidirect=False\n",
    "                 ):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # Embedding Layer\n",
    "\n",
    "        self.frag1_embed = nn.Embedding(num_embeddings=21,\n",
    "                                        embedding_dim=embed_dim,\n",
    "                                        padding_idx=0\n",
    "                                        )\n",
    "\n",
    "        self.c1 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=4)\n",
    "        self.p1 = nn.MaxPool1d(4, stride=1)\n",
    "        self.c2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.p2 = nn.MaxPool1d(3, stride=1)\n",
    "        self.c3 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=2)\n",
    "        self.p3 = nn.MaxPool1d(2, stride=1)\n",
    "        self.c4 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=1)\n",
    "        self.p4 = nn.MaxPool1d(1, stride=1)\n",
    "\n",
    "        # LSTM\n",
    "        self.frag1_lstm = nn.LSTM(input_size=128,\n",
    "                                  hidden_size=seq_dim,\n",
    "                                  batch_first=True,\n",
    "                                  bidirectional=lstm_bidirect\n",
    "                                  )\n",
    "\n",
    "        # Classifier\n",
    "        in_channels = seq_dim\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(in_features=in_channels, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, frag1):\n",
    "        BATCH_SIZE = frag1.size(0)\n",
    "        # Get Embedding Vector\n",
    "\n",
    "        frag1 = self.frag1_embed(frag1)\n",
    "\n",
    "        ###########################################################\n",
    "        frag1 = self.c1(frag1)\n",
    "        frag1 = self.p1(frag1)\n",
    "        frag1 = F.relu(frag1)\n",
    "        frag1 = self.c2(frag1)\n",
    "        frag1 = self.p2(frag1)\n",
    "        frag1 = F.relu(frag1)\n",
    "        frag1 = self.c3(frag1)\n",
    "        frag1 = self.p3(frag1)\n",
    "        frag1 = F.relu(frag1)\n",
    "        frag1 = self.c4(frag1)\n",
    "        frag1 = self.p4(frag1)\n",
    "        # frag1 = F.relu(frag1)\n",
    "        ################################################################\n",
    "\n",
    "        # LSTM\n",
    "        frag1_hidden, _ = self.frag1_lstm(frag1)\n",
    "        frag1_hidden = frag1_hidden[:, -1, :]\n",
    "\n",
    "        # Feature Concat -> Binary Classifier\n",
    "        x = self.regressor(frag1_hidden)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, test_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "\n",
    "    best_model = None\n",
    "    best_score = 9999999\n",
    "\n",
    "    for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for frag1, dist in tqdm(iter(train_loader)):\n",
    "            frag1 = frag1.to(device)\n",
    "            dist = dist.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(frag1)\n",
    "            loss = criterion(output, dist)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        val_loss, val_score = validation(model, val_loader, criterion, device)\n",
    "        print(\n",
    "            f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] Val RMSE : [{val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "\n",
    "        if best_score > val_score:\n",
    "            best_score = val_score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for frag1, dist in tqdm(iter(val_loader)):\n",
    "            frag1 = frag1.to(device)\n",
    "            dist = dist.float().to(device)\n",
    "\n",
    "            model_pred = model(frag1)\n",
    "\n",
    "            loss = criterion(model_pred, dist)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            preds += model_pred.tolist()\n",
    "            trues += dist.tolist()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    val_score = mean_squared_error(trues, preds, squared=False)  # squared=False : RMSE\n",
    "    return np.mean(val_loss), val_score\n",
    "\n",
    "\n",
    "model = BaseModel()\n",
    "\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,\n",
    "                                                       threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05f36e09",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a552ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df[\"frag_3\"] = 0\n",
    "test_df[\"frag_4\"] = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    test_df[\"frag_3\"][i] = test_df[\"frag_1\"][i][::-1]\n",
    "    test_df[\"frag_4\"][i] = test_df[\"frag_2\"][i][::-1]\n",
    "\n",
    "test_df[\"check_cha\"] = 0\n",
    "test_df[\"check_num\"] = 0\n",
    "\n",
    "for i in tqdm(range(len(test_df))):\n",
    "\n",
    "    if test_df[\"frag_1\"][i][0] in san and test_df[\"frag_2\"][i][0] in yum:\n",
    "        test_df[\"check_cha\"][i] = \"1-sanyum\"\n",
    "    if test_df[\"frag_1\"][i][0] in yum and test_df[\"frag_2\"][i][0] in san:\n",
    "        test_df[\"check_cha\"][i] = \"1-sanyum\"\n",
    "\n",
    "    if test_df[\"frag_1\"][i][0] in san and test_df[\"frag_2\"][i][-1] in yum:\n",
    "        test_df[\"check_cha\"][i] = \"2-sanyum\"\n",
    "    if test_df[\"frag_1\"][i][0] in yum and test_df[\"frag_2\"][i][-1] in san:\n",
    "        test_df[\"check_cha\"][i] = \"2-sanyum\"\n",
    "\n",
    "    if test_df[\"frag_1\"][i][-1] in san and test_df[\"frag_2\"][i][0] in yum:\n",
    "        test_df[\"check_cha\"][i] = \"3-sanyum\"\n",
    "    if test_df[\"frag_1\"][i][-1] in yum and test_df[\"frag_2\"][i][0] in san:\n",
    "        test_df[\"check_cha\"][i] = \"3-sanyum\"\n",
    "\n",
    "    if test_df[\"frag_1\"][i][-1] in san and test_df[\"frag_2\"][i][-1] in yum:\n",
    "        test_df[\"check_cha\"][i] = \"4-sanyum\"\n",
    "    if test_df[\"frag_1\"][i][-1] in yum and test_df[\"frag_2\"][i][-1] in san:\n",
    "        test_df[\"check_cha\"][i] = \"4-sanyum\"\n",
    "\n",
    "test_df[\"comb\"] = 0\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(test_df))):\n",
    "\n",
    "    if test_df[\"check_cha\"][i] == \"4-sanyum\":\n",
    "        test_df[\"comb\"][i] = test_df[\"frag_2\"][i] + test_df[\"frag_3\"][i]\n",
    "    if test_df[\"check_cha\"][i] == \"3-sanyum\":\n",
    "        test_df[\"comb\"][i] = test_df[\"frag_2\"][i] + test_df[\"frag_1\"][i]\n",
    "    if test_df[\"check_cha\"][i] == \"2-sanyum\":\n",
    "        test_df[\"comb\"][i] = test_df[\"frag_1\"][i] + test_df[\"frag_4\"][i]\n",
    "    if test_df[\"check_cha\"][i] == \"1-sanyum\":\n",
    "        test_df[\"comb\"][i] = test_df[\"frag_1\"][i] + test_df[\"frag_2\"][i]\n",
    "\n",
    "    else:\n",
    "        test_df[\"comb\"][i] = test_df[\"frag_1\"][i] + test_df[\"frag_2\"][i]\n",
    "\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "test_df[\"comb1\"] = 0\n",
    "\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    if len(test_df[\"comb\"][i]) <= 32:\n",
    "        test_df[\"comb1\"][i] = test_df[\"comb\"][i]\n",
    "    else:\n",
    "        test_df[\"comb1\"][i] = test_df[\"comb\"][i][(len(test_df[\"comb\"][i]) // 2) - 16:(len(test_df[\"comb\"][i]) // 2) + 16]\n",
    "\n",
    "test_df = test_df[[\"comb1\", \"comb\"]]\n",
    "\n",
    "test_frag1_list = get_preprocessing(test_df)\n",
    "\n",
    "test_dataset = CustomDataset(test_frag1_list, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for frag1 in tqdm(iter(test_loader)):\n",
    "            frag1 = frag1.to(device)\n",
    "\n",
    "            model_pred = model(frag1)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            preds += model_pred.tolist()\n",
    "    return preds\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)\n",
    "\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit['h_bond_distance'] = preds\n",
    "\n",
    "\n",
    "submit.to_csv('submition_real1_C1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
